{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "\n",
    "display_pca = False\n",
    "N_NEIGHBOURS = 5\n",
    "RANDOM_SEED = None\n",
    "\n",
    "blank_row = {\"Label\": '---', \n",
    "\t\t    \"Num Features\": '---', \n",
    "\t\t    \"Num Examples\": '---', \n",
    "\t\t    \"Training Size\": '---', \n",
    "\t\t    \"Minority Class\": '---', \n",
    "\t\t\t\"Base - Test C0 Acc\": '---', \n",
    "\t\t    \"Base - Test C1 Acc\": '---', \n",
    "\t\t    \"Base - Test Acc\": '---', \n",
    "\t\t\t\"Base - Val C0 Acc\": '---', \n",
    "\t\t    \"Base - Val C1 Acc\": '---', \n",
    "\t\t    \"Base - Val Acc\": '---', \n",
    "\t\t    \"Optimized - Test C0 Acc\": '---', \n",
    "\t\t    \"Optimized - Test C1 Acc\": '---', \n",
    "\t\t    \"Optimized - Test Acc\": '---', \n",
    "\t\t\t\"Num Examples for Test Best\": '---', \n",
    "\t\t\t\"Optimized - Val C0 Acc\": '---', \n",
    "\t\t    \"Optimized - Val C1 Acc\": '---', \n",
    "\t\t    \"Optimized - Val Acc\": '---', \n",
    "\t\t\t\"Num Examples for Val Best\": '---', \n",
    "\t\t\t\"Baseline IR\": '---', \n",
    "\t\t    \"Optimized IR\": '---'}\n",
    "\n",
    "all_headers = ['Label', \n",
    "               'Num Features', \n",
    "               'Num Examples', \n",
    "               'Training Size', \n",
    "               'Minority Class', \n",
    "               'Base - Test C0 Acc', \n",
    "               'Base - Test C1 Acc', \n",
    "               'Base - Test Acc', \n",
    "               'Base - Val C0 Acc', \n",
    "               'Base - Val C1 Acc', \n",
    "               'Base - Val Acc', \n",
    "               'Optimized - Test C0 Acc', \n",
    "               'Optimized - Test C1 Acc', \n",
    "               'Optimized - Test Acc', \n",
    "               'Num Examples for Test Best', \n",
    "               'Optimized - Val C0 Acc', \n",
    "               'Optimized - Val C1 Acc', \n",
    "               'Optimized - Val Acc', \n",
    "               'Num Examples for Val Best', \n",
    "               'Baseline IR', \n",
    "               'Optimized IR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops\n",
    "\t\n",
    "class InstanceSelectionProblem_2_Obj(Problem):\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val):\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=2,               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t# Calculate number of examples in each instance\n",
    "\t\tf1 = np.sum(x, axis=1)\n",
    "\n",
    "\t\t# Calculate inverse accuracy\n",
    "\t\tf2 = Parallel(n_jobs=-1)(delayed(self.train_model)(instance) for instance in x)\n",
    "\n",
    "\t\tout[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "\tdef train_model(self, instance):\n",
    "\t\tx_train_filtered, y_train_filtered = self.X_train[instance], self.y_train[instance]\n",
    "\t\t\n",
    "\t\tnum_included_instances = x_train_filtered.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= N_NEIGHBOURS:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\toptimization_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(self.X_val)\n",
    "\t\t\tacc = accuracy_score(self.y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "class InstanceSelectionProblem_3_Obj(Problem):\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val):\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=3,               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t# Calculate number of examples in each instance\n",
    "\t\tf1 = np.sum(x, axis=1)\n",
    "\n",
    "\t\t# Calculate inverse accuracy\n",
    "\t\tf2 = Parallel(n_jobs=-1)(delayed(self.train_model)(instance) for instance in x)\n",
    "\n",
    "\t\tf3 = Parallel(n_jobs=-1)(delayed(self.calculate_instance_IR)(instance) for instance in x)\n",
    "\t\t\n",
    "\t\tout[\"F\"] = np.column_stack([f1, f2, f3])\n",
    "\n",
    "\tdef calculate_instance_IR(self, instance):\n",
    "\t\tnum_1_class = np.sum(self.y_train[instance])\n",
    "\t\tnum_0_class = self.n_instances - num_1_class\n",
    "\t\tIR = max(num_0_class, num_1_class) / min(num_0_class, num_1_class)\n",
    "\t\treturn IR\n",
    "\n",
    "\tdef train_model(self, instance):\n",
    "\t\tx_train_filtered, y_train_filtered = self.X_train[instance], self.y_train[instance]\n",
    "\t\t\n",
    "\t\tnum_included_instances = x_train_filtered.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= N_NEIGHBOURS:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\toptimization_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(self.X_val)\n",
    "\t\t\tacc = accuracy_score(self.y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "class InstanceSelectionProblem_2_Obj_MinMaxAcc(Problem):\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val):\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=2,               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\tobjectives = Parallel(n_jobs=-1)(delayed(self.train_model)(instance) for instance in x)\n",
    "\t\tf1 = [obj[0] for obj in objectives] # Class 0 error\n",
    "\t\tf2 = [obj[1] for obj in objectives] # Class 1 error\n",
    "\t\tout[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "\tdef train_model(self, instance):\n",
    "\t\tx_train_filtered, y_train_filtered = self.X_train[instance], self.y_train[instance]\n",
    "\t\tnum_included_instances = x_train_filtered.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= N_NEIGHBOURS:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\toptimization_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\n",
    "\t\t\tclass_1_indices = np.where(self.y_val==1)\n",
    "\t\t\tclass_0_indices = np.where(self.y_val==0)\n",
    "\n",
    "\t\t\tclass_1_x_val = self.X_val[class_1_indices]\n",
    "\t\t\tclass_0_x_val = self.X_val[class_0_indices]\n",
    "\n",
    "\t\t\tclass_1_y_val = self.y_val[class_1_indices]\n",
    "\t\t\tclass_0_y_val = self.y_val[class_0_indices]\n",
    "\t\t\t\n",
    "\t\t\tclass_1_pred = optimization_knn.predict(class_1_x_val)\n",
    "\t\t\tclass_1_acc = accuracy_score(class_1_y_val, class_1_pred)\n",
    "\n",
    "\t\t\tclass_0_pred = optimization_knn.predict(class_0_x_val)\n",
    "\t\t\tclass_0_acc = accuracy_score(class_0_y_val, class_0_pred)\n",
    "\n",
    "\t\t\treturn (1-class_0_acc, 1-class_1_acc)\n",
    "\t\telse:\n",
    "\t\t\treturn (1, 1)\n",
    "\n",
    "def parse_dataset(path, name, over_sample=False):\n",
    "\ttry:\n",
    "\t\tdf = pd.read_csv(path, delimiter=', ', engine='python')\n",
    "\t\tX = df.drop(columns='Class')\n",
    "\t\ty = df['Class']\n",
    "\texcept KeyError:\n",
    "\t\tdf = pd.read_csv(path, delimiter=',')\n",
    "\t\tX = df.drop(columns='Class')\n",
    "\t\ty = df['Class']\n",
    "\n",
    "\t# Generate train, validation, and test sets\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty_encoded = label_encoder.fit_transform(y)\n",
    "\tX_train, X_val, X_test, y_train, y_val, y_test = split_and_scale_datasets(X, y_encoded, random_state=RANDOM_SEED)\n",
    "\n",
    "\tif over_sample:\n",
    "\t\tclass_0_count, class_1_count, IR = set_summary(y_train, \"y_train\", False)\n",
    "\t\tif class_0_count > class_1_count:\n",
    "\t\t\tminority_class_indicies = np.where(y_train == 1)\n",
    "\t\telse:\n",
    "\t\t\tminority_class_indicies = np.where(y_train == 0)\n",
    "\n",
    "\t\tX_train = np.concatenate((X_train, X_train[minority_class_indicies]), axis=0)\n",
    "\t\ty_train = np.concatenate((y_train, y_train[minority_class_indicies]), axis=0)\n",
    "\n",
    "\treturn [X, y, X_train, X_val, X_test, y_train, y_val, y_test, name]\n",
    "\n",
    "def class_based_accuracy(model, x, y):\n",
    "\tclass_1_indices = np.where(y==1)\n",
    "\tclass_0_indices = np.where(y==0)\n",
    "\n",
    "\tclass_1_x = x[class_1_indices]\n",
    "\tclass_0_x = x[class_0_indices]\n",
    "\n",
    "\tclass_1_y = y[class_1_indices]\n",
    "\tclass_0_y = y[class_0_indices]\n",
    "\t\n",
    "\tclass_1_pred = model.predict(class_1_x)\n",
    "\tclass_1_acc = accuracy_score(class_1_y, class_1_pred)\n",
    "\n",
    "\tclass_0_pred = model.predict(class_0_x)\n",
    "\tclass_0_acc = accuracy_score(class_0_y, class_0_pred)\n",
    "\n",
    "\toverall_prediction = model.predict(x)\n",
    "\toverall_accuracy = accuracy_score(y, overall_prediction)\n",
    "\n",
    "\treturn class_0_acc, class_1_acc, overall_accuracy\n",
    "\n",
    "def assess_baseline_metrics(X_train, y_train, X_test, y_test):\n",
    "\n",
    "\tcounts = pd.DataFrame(y_train).value_counts()\n",
    "\n",
    "\t# Determine baseline accuracy of classifier on all examples\n",
    "\tbaseline_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\tbaseline_knn.fit(X_train, y_train)\n",
    "\tclass_0_baseline_testAcc, class_1_baseline_testAcc, baseline_testAcc = class_based_accuracy(baseline_knn, X_test, y_test)\n",
    "\n",
    "\treturn counts, class_0_baseline_testAcc, class_1_baseline_testAcc, baseline_testAcc\n",
    "\n",
    "def execute_optimization(X_train, y_train, X_val, y_val, problem_defn, sampler):\n",
    "\t\n",
    "\tproblem = problem_defn(X_train, y_train, X_val, y_val)\n",
    "\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=100, \n",
    "\t\tsampling=sampler, \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True)\n",
    "\t\n",
    "\treturn minimize(problem, algorithm, ('n_gen', 100), verbose=False, seed=RANDOM_SEED)\n",
    "\n",
    "def select_optimal_instance(X_train, y_train, X_val, y_val, result):\n",
    "\n",
    "\tfronts = NonDominatedSorting().do(result.F, only_non_dominated_front=True)\n",
    "\t_, pareto_indicies = np.unique(result.F[fronts], axis=0, return_index=True)\n",
    "\n",
    "\tbest_instance_idx = 0\n",
    "\tbest_acc = 0\n",
    "\tfor idx, instance in enumerate(result.X[pareto_indicies]):\n",
    "\t\tx_filtered, y_filtered = X_train[instance], y_train[instance]\n",
    "\t\tif x_filtered.shape[0] < N_NEIGHBOURS: \n",
    "\t\t\tacc = 1\n",
    "\t\telse:\n",
    "\t\t\tknn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\t\ty_pred = knn.predict(X_val)\n",
    "\t\t\tacc = accuracy_score(y_val, y_pred)\n",
    "\t\t\n",
    "\t\tif acc > best_acc:\n",
    "\t\t\tbest_acc = acc\n",
    "\t\t\tbest_instance_idx = idx\n",
    "\t\n",
    "\treturn best_acc, best_instance_idx, x_filtered, y_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RjKim\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "iter_resuls = []\n",
    "for iter in range(10):\n",
    "\tfor data_option in ['over_sample', 'regular_sample']:\n",
    "\t\tfor init_pop in ['rand', 'bias']:\n",
    "\t\t\tfor optimization in ['MinMajAcc', '2Obj', '3Obj']:\n",
    "\t\t\t\tfor folder in os.listdir('Datasets'):\n",
    "\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(\n",
    "\t\t\t\t\t\t\tos.path.join('Datasets', folder, f\"{folder}.csv\"), \n",
    "\t\t\t\t\t\t\tfolder, \n",
    "\t\t\t\t\t\t\tover_sample=True if data_option == \"over_sample \" else False\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\tinitial_population = BinaryRandomSampling() if init_pop == \"rand\" else BiasedBinarySampling(y_train, 0.5, 0.7)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tproblem_defn_mapping = {\n",
    "\t\t\t\t\t\t\t\"MinMajAcc\": InstanceSelectionProblem_2_Obj_MinMaxAcc,\n",
    "\t\t\t\t\t\t\t\"2Obj\": InstanceSelectionProblem_2_Obj,\n",
    "\t\t\t\t\t\t\t\"3Obj\": InstanceSelectionProblem_3_Obj\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\t\tresult = execute_optimization(\n",
    "\t\t\t\t\t\t\tX_train, y_train, X_val, y_val, \n",
    "\t\t\t\t\t\t\tproblem_defn_mapping[optimization], \n",
    "\t\t\t\t\t\t\tinitial_population\n",
    "\t\t\t\t\t\t)\n",
    "\n",
    "\t\t\t\t\t\tsave_var = {\n",
    "\t\t\t\t\t\t\t\"iter\": iter,\n",
    "\t\t\t\t\t\t\t\"Sampler\": data_option,\n",
    "\t\t\t\t\t\t\t\"Population\": init_pop,\n",
    "\t\t\t\t\t\t\t\"Optimization\": optimization,\n",
    "\t\t\t\t\t\t\t\"Dataset\": folder,\n",
    "\t\t\t\t\t\t\t\"Result\": result,\n",
    "\t\t\t\t\t\t\t\"Data\": (X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "\t\t\t\t\t\t}\n",
    "\n",
    "\t\t\t\t\t\twith open(f\"Experiments//{iter}__{data_option}__{init_pop}__{optimization}__{folder}.pickle\", \"wb\") as fh:\n",
    "\t\t\t\t\t\t\tpickle.dump(save_var, fh, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\t\t\t\t\texcept Exception as e:\n",
    "\t\t\t\t\t\tprint(f\"Error, {e} - {iter} - {data_option} - {init_pop} - {optimization} - {folder}\")\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\tbreak\n",
    "\t\t\tbreak\n",
    "\t\tbreak\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936046511627907\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(\"Experiments\"):\n",
    "    \n",
    "\twith open(f'Experiments//{file}', 'rb') as fh:\n",
    "\t\tsave_var = pickle.load(fh)\n",
    "\n",
    "\tX_train, X_val, X_test, y_train, y_val, y_test = save_var['Data']\n",
    "\n",
    "\tbest_acc, best_instance_idx, x_filtered, y_filtered = select_optimal_instance(X_train, y_train, X_val, y_val, save_var['Result'])\n",
    "\t\n",
    "\tprint(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 0 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 0 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 0 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 0 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 0 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 0 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 0 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 0 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 0 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 0 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 0 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 0 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 0 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 0 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 0 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 0 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 0 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 0 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 0 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 0 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 0 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 1 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 1 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 1 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 1 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 1 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 1 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 1 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 1 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 1 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 1 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 1 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 1 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 1 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 1 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 1 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 1 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 1 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 1 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 1 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 1 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 1 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 1 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 2 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 2 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 2 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 2 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 2 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 2 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 2 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 2 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 2 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 2 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 2 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 2 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 2 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 2 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 2 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 2 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 2 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 2 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 2 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 2 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 2 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 2 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 3 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 3 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 3 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 3 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 3 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 3 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 3 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 3 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 3 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 3 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 3 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 3 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 3 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 3 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 3 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 3 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 3 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 3 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 3 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 3 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 3 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 3 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 4 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 4 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 4 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 4 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 4 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 4 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 4 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 4 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 4 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 4 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 4 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 4 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 4 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 4 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 4 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 4 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 4 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 4 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 4 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 4 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 4 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 4 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 5 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 5 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 5 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 5 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 5 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 5 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 5 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 5 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 5 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 5 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 5 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 5 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 5 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 5 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 5 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 5 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 5 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 5 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 5 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 5 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 5 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 5 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 6 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 6 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 6 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 6 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 6 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 6 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 6 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 6 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 6 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 6 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 6 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 6 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 6 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 6 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 6 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 6 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 6 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 6 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 6 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 6 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 6 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 6 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 7 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 7 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 7 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 7 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 7 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 7 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 7 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 7 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 7 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 7 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 7 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 7 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 7 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 7 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 7 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 7 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 7 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 7 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 7 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 7 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 7 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 7 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 8 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 8 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 8 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 8 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 8 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 8 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 8 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 8 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 8 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 8 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 8 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 8 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 8 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 8 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 8 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 8 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 8 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 8 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 8 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 8 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 8 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 8 - regular_sample-bias-MinMajAcc-yeast1\n",
      "Iter 9 - over_sample-rand-MinMajAcc-australian\n",
      "Iter 9 - over_sample-rand-MinMajAcc-bupa\n",
      "Iter 9 - over_sample-rand-MinMajAcc-glass1\n",
      "Iter 9 - over_sample-rand-MinMajAcc-magic\n",
      "Iter 9 - over_sample-rand-MinMajAcc-phoneme\n",
      "Iter 9 - over_sample-rand-MinMajAcc-pima\n",
      "Iter 9 - over_sample-rand-MinMajAcc-segment0\n",
      "Iter 9 - over_sample-rand-MinMajAcc-sonar\n",
      "Iter 9 - over_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 9 - over_sample-rand-MinMajAcc-yeast1\n",
      "Iter 9 - over_sample-bias-MinMajAcc-australian\n",
      "Iter 9 - over_sample-bias-MinMajAcc-bupa\n",
      "Iter 9 - over_sample-bias-MinMajAcc-glass1\n",
      "Iter 9 - over_sample-bias-MinMajAcc-magic\n",
      "Iter 9 - over_sample-bias-MinMajAcc-phoneme\n",
      "Iter 9 - over_sample-bias-MinMajAcc-pima\n",
      "Iter 9 - over_sample-bias-MinMajAcc-segment0\n",
      "Iter 9 - over_sample-bias-MinMajAcc-sonar\n",
      "Iter 9 - over_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 9 - over_sample-bias-MinMajAcc-yeast1\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-australian\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-bupa\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-glass1\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-magic\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-phoneme\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-pima\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-segment0\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-sonar\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-vehicle0\n",
      "Iter 9 - regular_sample-rand-MinMajAcc-yeast1\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-australian\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-bupa\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-glass1\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-magic\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-phoneme\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-pima\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-segment0\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-sonar\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-vehicle0\n",
      "Iter 9 - regular_sample-bias-MinMajAcc-yeast1\n"
     ]
    }
   ],
   "source": [
    "iter_resuls = []\n",
    "for iter in range(10):\n",
    "\tfor data_option in ['over_sample', 'regular_sample']:\n",
    "\t\tfor init_pop in ['rand', 'bias']:\n",
    "\t\t\tfor optimization in ['MinMajAcc']:#, '2Obj', '3Obj']:\n",
    "\t\t\t\tfor folder in os.listdir('Datasets'):\n",
    "\t\t\t\t\tover_sample = False if data_option == \"regular_sample\" else True\n",
    "\t\t\t\t\trun_id = f\"{data_option}-{init_pop}-{optimization}-{folder}\"\n",
    "\t\t\t\t\tprint(f\"Iter {iter} - {run_id}\")\n",
    "\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summations = {}\n",
    "for result in iter_results:\n",
    "\t\n",
    "\tif result['Label'] not in summations:\n",
    "\t\tsummations[result['Label']] = {}\n",
    "\t\tfor key in result:\n",
    "\t\t\tif isinstance(result[key], float) or isinstance(result[key], int):\n",
    "\t\t\t\tsummations[result['Label']][key] = 0\n",
    "\t\n",
    "\tfor key in result:\n",
    "\t\tif key in summations[result['Label']]:\n",
    "\t\t\tsummations[result['Label']][key] += result[key]\n",
    "\t\n",
    "\t\n",
    "\n",
    "averages = []\n",
    "for label in summations:\n",
    "\ttemp = {}\n",
    "\tfor key in summations[label]:\n",
    "\t\ttemp[key] = summations[label][key] / 10\n",
    "\t\n",
    "\ttemp[\"Label\"] = label\n",
    "\taverages.append(temp)\n",
    "\n",
    "pd.DataFrame(averages).to_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
