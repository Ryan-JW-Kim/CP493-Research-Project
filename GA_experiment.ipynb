{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.core.problem import Problem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.core.sampling import Sampling\n",
    "from pymoo.operators.crossover.hux import HUX\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "from pymoo.operators.sampling.rnd import BinaryRandomSampling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils import *\n",
    "\n",
    "display_pca = False\n",
    "N_NEIGHBOURS = 5\n",
    "\n",
    "blank_row = {\"Label\": '---', \n",
    "\t\t    \"Num Features\": '---', \n",
    "\t\t    \"Num Examples\": '---', \n",
    "\t\t    \"Training Size\": '---', \n",
    "\t\t    \"Minority Class\": '---', \n",
    "\t\t\t\"Base - Test C0 Acc\": '---', \n",
    "\t\t    \"Base - Test C1 Acc\": '---', \n",
    "\t\t    \"Base - Test Acc\": '---', \n",
    "\t\t\t\"Base - Val C0 Acc\": '---', \n",
    "\t\t    \"Base - Val C1 Acc\": '---', \n",
    "\t\t    \"Base - Val Acc\": '---', \n",
    "\t\t    \"Optimized - Test C0 Acc\": '---', \n",
    "\t\t    \"Optimized - Test C1 Acc\": '---', \n",
    "\t\t    \"Optimized - Test Acc\": '---', \n",
    "\t\t\t\"Num Examples for Test Best\": '---', \n",
    "\t\t\t\"Optimized - Val C0 Acc\": '---', \n",
    "\t\t    \"Optimized - Val C1 Acc\": '---', \n",
    "\t\t    \"Optimized - Val Acc\": '---', \n",
    "\t\t\t\"Num Examples for Val Best\": '---', \n",
    "\t\t\t\"Baseline IR\": '---', \n",
    "\t\t    \"Optimized IR\": '---'}\n",
    "\n",
    "all_headers = ['Label', \n",
    "               'Num Features', \n",
    "               'Num Examples', \n",
    "               'Training Size', \n",
    "               'Minority Class', \n",
    "               'Base - Test C0 Acc', \n",
    "               'Base - Test C1 Acc', \n",
    "               'Base - Test Acc', \n",
    "               'Base - Val C0 Acc', \n",
    "               'Base - Val C1 Acc', \n",
    "               'Base - Val Acc', \n",
    "               'Optimized - Test C0 Acc', \n",
    "               'Optimized - Test C1 Acc', \n",
    "               'Optimized - Test Acc', \n",
    "               'Num Examples for Test Best', \n",
    "               'Optimized - Val C0 Acc', \n",
    "               'Optimized - Val C1 Acc', \n",
    "               'Optimized - Val Acc', \n",
    "               'Num Examples for Val Best', \n",
    "               'Baseline IR', \n",
    "               'Optimized IR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasedBinarySampling(Sampling):\n",
    "\tdef __init__(self, labels, major_prob, minor_prob):\n",
    "\t\t\n",
    "\t\tself.labels = labels\n",
    "\t\tcounts = pd.DataFrame(labels).value_counts()\n",
    "\t\tif counts[0] > counts[1]:\n",
    "\t\t\tself.c0_thresh = major_prob\n",
    "\t\t\tself.c1_thresh = minor_prob\n",
    "\t\telse:\n",
    "\t\t\tself.c0_thresh = minor_prob\n",
    "\t\t\tself.c1_thresh = major_prob\n",
    "\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\tdef _do(self, problem, n_samples, **kwargs):\n",
    "\n",
    "\t\trands = np.random.random((n_samples, problem.n_var))\n",
    "\t\tinit_pops = np.zeros((n_samples, problem.n_var), dtype=bool)\n",
    "\n",
    "\t\tfor idx, label in enumerate(self.labels):\n",
    "\t\t\tif label == 0:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c0_thresh).astype(bool)\n",
    "\t\t\tif label == 1:\n",
    "\t\t\t\tinit_pops[:, idx] = (rands[:, idx] < self.c1_thresh).astype(bool)\n",
    "\n",
    "\n",
    "\t\treturn init_pops\n",
    "\t\n",
    "class InstanceSelectionProblem_2_Obj(Problem):\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val):\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=2,               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t# Calculate number of examples in each instance\n",
    "\t\tf1 = np.sum(x, axis=1)\n",
    "\n",
    "\t\t# Calculate inverse accuracy\n",
    "\t\tf2 = Parallel(n_jobs=-1)(delayed(self.train_model)(instance) for instance in x)\n",
    "\n",
    "\t\tout[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "\tdef train_model(self, instance):\n",
    "\t\tx_train_filtered, y_train_filtered = self.X_train[instance], self.y_train[instance]\n",
    "\t\t\n",
    "\t\tnum_included_instances = x_train_filtered.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= N_NEIGHBOURS:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\toptimization_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(self.X_val)\n",
    "\t\t\tacc = accuracy_score(self.y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "class InstanceSelectionProblem_3_Obj(Problem):\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val):\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=3,               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\t# Calculate number of examples in each instance\n",
    "\t\tf1 = np.sum(x, axis=1)\n",
    "\n",
    "\t\t# Calculate inverse accuracy\n",
    "\t\tf2 = Parallel(n_jobs=-1)(delayed(self.train_model)(instance) for instance in x)\n",
    "\n",
    "\t\tf3 = Parallel(n_jobs=-1)(delayed(self.calculate_instance_IR)(instance) for instance in x)\n",
    "\t\t\n",
    "\t\tout[\"F\"] = np.column_stack([f1, f2, f3])\n",
    "\n",
    "\tdef calculate_instance_IR(self, instance):\n",
    "\t\tnum_1_class = np.sum(self.y_train[instance])\n",
    "\t\tnum_0_class = self.n_instances - num_1_class\n",
    "\t\tIR = max(num_0_class, num_1_class) / min(num_0_class, num_1_class)\n",
    "\t\treturn IR\n",
    "\n",
    "\tdef train_model(self, instance):\n",
    "\t\tx_train_filtered, y_train_filtered = self.X_train[instance], self.y_train[instance]\n",
    "\t\t\n",
    "\t\tnum_included_instances = x_train_filtered.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= N_NEIGHBOURS:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\toptimization_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\n",
    "\t\t\ty_pred = optimization_knn.predict(self.X_val)\n",
    "\t\t\tacc = accuracy_score(self.y_val, y_pred)\n",
    "\t\t\treturn 1-acc\n",
    "\t\telse:\n",
    "\t\t\treturn 1\n",
    "\n",
    "class InstanceSelectionProblem_2_Obj_MinMaxAcc(Problem):\n",
    "\tdef __init__(self, X_train, y_train, X_val, y_val):\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\tself.y_train = y_train\n",
    "\n",
    "\t\tself.X_val = X_val\n",
    "\t\tself.y_val = y_val\n",
    "\n",
    "\t\tself.training_data = X_train\n",
    "\t\tself.n_instances = X_train.shape[0]\n",
    "\t\t\n",
    "\t\tsuper().__init__(\n",
    "\t\t\tn_var=self.n_instances,\n",
    "\t\t\tn_obj=2,               \n",
    "\t\t\tn_constr=0,            \n",
    "\t\t\txl=0,                  \n",
    "\t\t\txu=1,                  \n",
    "\t\t\ttype_var=np.bool_,     \n",
    "\t\t)\n",
    "\n",
    "\tdef _evaluate(self, x, out, *args, **kwargs):\n",
    "\t\tobjectives = Parallel(n_jobs=-1)(delayed(self.train_model)(instance) for instance in x)\n",
    "\t\tf1 = [obj[0] for obj in objectives] # Class 0 error\n",
    "\t\tf2 = [obj[1] for obj in objectives] # Class 1 error\n",
    "\t\tout[\"F\"] = np.column_stack([f1, f2])\n",
    "\n",
    "\tdef train_model(self, instance):\n",
    "\t\tprint(f\">>>> {instance}\")\n",
    "\t\tx_train_filtered, y_train_filtered = self.X_train[instance], self.y_train[instance]\n",
    "\t\tnum_included_instances = x_train_filtered.shape[0]\n",
    "\n",
    "\t\tif num_included_instances >= N_NEIGHBOURS:\n",
    "\t\t\toptimization_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\toptimization_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\n",
    "\t\t\tclass_1_indices = np.where(self.y_val==1)\n",
    "\t\t\tclass_0_indices = np.where(self.y_val==0)\n",
    "\n",
    "\t\t\tclass_1_x_val = self.X_val[class_1_indices]\n",
    "\t\t\tclass_0_x_val = self.X_val[class_0_indices]\n",
    "\n",
    "\t\t\tclass_1_y_val = self.y_val[class_1_indices]\n",
    "\t\t\tclass_0_y_val = self.y_val[class_0_indices]\n",
    "\t\t\t\n",
    "\t\t\tclass_1_pred = optimization_knn.predict(class_1_x_val)\n",
    "\t\t\tclass_1_acc = accuracy_score(class_1_y_val, class_1_pred)\n",
    "\n",
    "\t\t\tclass_0_pred = optimization_knn.predict(class_0_x_val)\n",
    "\t\t\tclass_0_acc = accuracy_score(class_0_y_val, class_0_pred)\n",
    "\n",
    "\t\t\treturn (1-class_0_acc, 1-class_1_acc)\n",
    "\t\telse:\n",
    "\t\t\treturn (1, 1)\n",
    "\n",
    "def report_table_1(results):\n",
    "\tdisplay_columns = ['Label', 'Num Features', 'Num Examples', 'Training Size', 'Minority Class', '-----', 'Baseline IR', 'Optimized IR']\n",
    "\tdata = []\n",
    "\tfor result in results:\n",
    "\t\tdata.append([])\n",
    "\t\tfor idx, key in enumerate(display_columns):\n",
    "\t\t\tif key in result:\n",
    "\t\t\t\tdata[-1].append(result[key])\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata[-1].append(\"--\")\n",
    "\t\t\t\t\t\t\t\n",
    "\treturn pd.DataFrame(data, columns=display_columns)\n",
    "\n",
    "def report_table_2(results):\n",
    "\tdisplay_columns = ['Label', \n",
    "\t\t\t\t\t'Base - Test Acc', \n",
    "\t\t\t\t\t'Base - Test C0 Acc', \n",
    "\t\t\t\t\t'Base - Test C1 Acc', \n",
    "\t\t\t\t\t'-----',\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t'Optimized - Test Acc', \n",
    "\t\t\t\t\t'Optimized - Test C0 Acc', \n",
    "\t\t\t\t\t'Optimized - Test C1 Acc', \n",
    "\t\t\t\t\t'Num Examples for Test Best', \n",
    "\t\t\t\t\t'-----',\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t'Optimized - Val Acc', \n",
    "\t\t\t\t\t'Optimized - Val C0 Acc', \n",
    "\t\t\t\t\t'Optimized - Val C1 Acc', \n",
    "\t\t\t\t\t'Num Examples for Val Best']\n",
    "\tdata = []\n",
    "\tfor result in results:\n",
    "\t\tdata.append([])\n",
    "\t\tfor idx, key in enumerate(display_columns):\n",
    "\t\t\tif key in result:\n",
    "\t\t\t\tdata[-1].append(result[key])\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata[-1].append(\"-----\")\n",
    "\t\t\t\t\t\t\t\n",
    "\treturn pd.DataFrame(data, columns=display_columns)\n",
    "\t\n",
    "def parse_dataset(path, name, over_sample=False, random_state=None):\n",
    "\ttry:\n",
    "\t\tdf = pd.read_csv(path, delimiter=', ')\n",
    "\t\tX = df.drop(columns='Class')\n",
    "\t\ty = df['Class']\n",
    "\texcept KeyError:\n",
    "\t\tdf = pd.read_csv(path, delimiter=',')\n",
    "\t\tX = df.drop(columns='Class')\n",
    "\t\ty = df['Class']\n",
    "\n",
    "\t# Generate train, validation, and test sets\n",
    "\tlabel_encoder = LabelEncoder()\n",
    "\ty_encoded = label_encoder.fit_transform(y)\n",
    "\tX_train, X_val, X_test, y_train, y_val, y_test = split_and_scale_datasets(X, y_encoded, random_state=random_state)\n",
    "\n",
    "\tif over_sample:\n",
    "\t\tclass_0_count, class_1_count, IR = set_summary(y_train, \"y_train\", False)\n",
    "\t\tif class_0_count > class_1_count:\n",
    "\t\t\tminority_class_indicies = np.where(y_train == 1)\n",
    "\t\telse:\n",
    "\t\t\tminority_class_indicies = np.where(y_train == 0)\n",
    "\n",
    "\t\tX_train = np.concatenate((X_train, X_train[minority_class_indicies]), axis=0)\n",
    "\t\ty_train = np.concatenate((y_train, y_train[minority_class_indicies]), axis=0)\n",
    "\n",
    "\treturn [X, y, X_train, X_val, X_test, y_train, y_val, y_test, name]\n",
    "\n",
    "def class_based_accuracy(model, x, y):\n",
    "\tclass_1_indices = np.where(y==1)\n",
    "\tclass_0_indices = np.where(y==0)\n",
    "\n",
    "\tclass_1_x = x[class_1_indices]\n",
    "\tclass_0_x = x[class_0_indices]\n",
    "\n",
    "\tclass_1_y = y[class_1_indices]\n",
    "\tclass_0_y = y[class_0_indices]\n",
    "\t\n",
    "\tclass_1_pred = model.predict(class_1_x)\n",
    "\tclass_1_acc = accuracy_score(class_1_y, class_1_pred)\n",
    "\n",
    "\tclass_0_pred = model.predict(class_0_x)\n",
    "\tclass_0_acc = accuracy_score(class_0_y, class_0_pred)\n",
    "\n",
    "\toverall_prediction = model.predict(x)\n",
    "\toverall_accuracy = accuracy_score(y, overall_prediction)\n",
    "\n",
    "\treturn class_0_acc, class_1_acc, overall_accuracy\n",
    "\n",
    "def execute_regular_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, problem_defn, sampler, random_state=None):\n",
    "\tprint(f\"Executing {problem_defn} on {name}...\")\n",
    "\t\n",
    "\tnum_examples, num_features = set_summary(X, 'x', print_res=False)\n",
    "\ttrain_class_0_count, train_class_1_count, train_baseline_IR = set_summary(y_train, 'y', print_res=False)\n",
    "\tminority_class = 0 if min(train_class_0_count, train_class_1_count) == train_class_0_count else 1\n",
    "\n",
    "\t# Determine baseline accuracy of classifier on all examples\n",
    "\tbaseline_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\tbaseline_knn.fit(X_train, y_train)\n",
    "\tclass_0_baseline_testAcc, class_1_baseline_testAcc, baseline_testAcc = class_based_accuracy(baseline_knn, X_test, y_test)\n",
    "\tclass_0_baseline_valAcc, class_1_baseline_valAcc, baseline_valAcc = class_based_accuracy(baseline_knn, X_val, y_val)\n",
    "\t\n",
    "\t# Execute the optimization algorithm\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=100, \n",
    "\t\tsampling=sampler, \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True\n",
    "\t)\n",
    "\tproblem = problem_defn(X_train, y_train, X_val, y_val)\n",
    "\tres = minimize(problem, algorithm, ('n_gen', 100), verbose=False, seed=random_state)\n",
    "\n",
    "\t# Calculate the best instance and extract its values\n",
    "\tfronts = NonDominatedSorting().do(res.F, only_non_dominated_front=True)\n",
    "\tunique_F, unique_indices = np.unique(res.F[fronts], axis=0, return_index=True)\n",
    "\tbest_instance_idx = np.argmin(unique_F[:,1])\n",
    "\tnum_instance_in_best_solution = unique_F[best_instance_idx, 0]\n",
    "\tbest_instance = res.X[unique_indices[best_instance_idx]]\n",
    "\t\n",
    "\t# Calculate the optimized accuracy of the best instance\n",
    "\tx_train_filtered, y_train_filtered = X_train[best_instance], y_train[best_instance]\n",
    "\t_, _, optimized_IR = set_summary(y_train_filtered, 'y', print_res=False)\n",
    "\n",
    "\t# Calculate the optimized accuracy of the best instance on test set and validation set\n",
    "\toptimized_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimized_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\tclass_0_optimized_testAcc, class_1_optimized_testAcc, optimized_testAcc = class_based_accuracy(optimized_knn, X_test, y_test)\n",
    "\tclass_0_optimized_valAcc, class_1_optimized_valAcc, optimized_valAcc = class_based_accuracy(optimized_knn, X_val, y_val)\n",
    "\t\n",
    "\ttest_pareto_front = []\n",
    "\tbest_test_instance = [-1, 1]\n",
    "\tfor instance in res.X[unique_indices]:\n",
    "\t\tx_filtered, y_filtered = X_train[instance], y_train[instance]\n",
    "\t\tif x_filtered.shape[0] < N_NEIGHBOURS: error = 1\n",
    "\t\telse:\n",
    "\t\t\tknn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\t\ty_pred = knn.predict(X_test)\n",
    "\t\t\terror = 1 - accuracy_score(y_test, y_pred)\n",
    "\t\t\n",
    "\t\tif best_test_instance[1] > error:\n",
    "\t\t\tbest_test_instance = [x_filtered.shape[0], error]\n",
    "\t\ttest_pareto_front.append([x_filtered.shape[0], error])\n",
    "\tx2, y2 = [row[0] for row in test_pareto_front], [row[1] for row in test_pareto_front]\n",
    "\tx1, y1 = [row[0] for row in unique_F], [row[1] for row in unique_F]\n",
    "\tplt.ylim((0, 1))\n",
    "\tplt.title(name)\n",
    "\tplt.ylabel(\"f2 *\")\n",
    "\tplt.xlabel(\"f1\")\n",
    "\tplt.scatter(x1, y1, c='b')\n",
    "\tplt.scatter(x2, y2, c='r')\n",
    "\tplt.show()\n",
    "\n",
    "\treturn {\"Label\": name, \n",
    "\t\t    \"Num Features\": num_features, \n",
    "\t\t    \"Num Examples\": num_examples,\n",
    "\t\t    \"Training Size\": X_train.shape[0],\n",
    "\t\t    \"Minority Class\": minority_class,\n",
    "\t\t    \n",
    "\t\t\t\"Base - Test C0 Acc\": round(class_0_baseline_testAcc*100,2), \n",
    "\t\t    \"Base - Test C1 Acc\": round(class_1_baseline_testAcc*100,2), \n",
    "\t\t    \"Base - Test Acc\": round(baseline_testAcc*100,2), \n",
    "\n",
    "\t\t\t\"Base - Val C0 Acc\": round(class_0_baseline_valAcc*100,2), \n",
    "\t\t    \"Base - Val C1 Acc\": round(class_1_baseline_valAcc*100,2), \n",
    "\t\t    \"Base - Val Acc\": round(baseline_valAcc*100,2), \n",
    "\n",
    "\t\t    \"Optimized - Test C0 Acc\": round(class_0_optimized_testAcc*100,2), \n",
    "\t\t    \"Optimized - Test C1 Acc\": round(class_1_optimized_testAcc*100,2), \n",
    "\t\t    \"Optimized - Test Acc\": round(optimized_testAcc*100,2), \n",
    "\t\t\t\"Num Examples for Test Best\": best_test_instance[0],\n",
    "\t\t\t\n",
    "\t\t\t\"Optimized - Val C0 Acc\": round(class_0_optimized_valAcc*100,2), \n",
    "\t\t    \"Optimized - Val C1 Acc\": round(class_1_optimized_valAcc*100,2), \n",
    "\t\t    \"Optimized - Val Acc\": round(optimized_valAcc*100,2), \n",
    "\t\t\t\"Num Examples for Val Best\": num_instance_in_best_solution,\n",
    "\t\t    \n",
    "\t\t\t\"Baseline IR\": train_baseline_IR,\n",
    "\t\t    \"Optimized IR\": optimized_IR}\n",
    "\n",
    "def execute_class_sensitive_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, problem_defn, sampler, random_state=None):\n",
    "\tprint(f\"Executing {problem_defn} on {name}...\")\n",
    "\t\n",
    "\tnum_examples, num_features = set_summary(X, 'x', print_res=False)\n",
    "\ttrain_class_0_count, train_class_1_count, train_baseline_IR = set_summary(y_train, 'y', print_res=False)\n",
    "\tminority_class = 0 if min(train_class_0_count, train_class_1_count) == train_class_0_count else 1\n",
    "\n",
    "\t# Determine baseline accuracy of classifier on all examples\n",
    "\tbaseline_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\tbaseline_knn.fit(X_train, y_train)\n",
    "\tclass_0_baseline_testAcc, class_1_baseline_testAcc, baseline_testAcc = class_based_accuracy(baseline_knn, X_test, y_test)\n",
    "\tclass_0_baseline_valAcc, class_1_baseline_valAcc, baseline_valAcc = class_based_accuracy(baseline_knn, X_val, y_val)\n",
    "\n",
    "\t# Execute the optimization algorithm\n",
    "\tproblem = problem_defn(X_train, y_train, X_val, y_val)\n",
    "\talgorithm = NSGA2(\n",
    "\t\tpop_size=100, \n",
    "\t\tsampling=sampler, \n",
    "\t\tcrossover=HUX(), \n",
    "\t\tmutation=BitflipMutation(), \n",
    "\t\teliminate_duplicates=True)\n",
    "\t\n",
    "\tres = minimize(problem, algorithm, ('n_gen', 100), verbose=False, seed=random_state)\n",
    "\n",
    "\t# Calculate the first rank pareto front\n",
    "\tfronts = NonDominatedSorting().do(res.F, only_non_dominated_front=True)\n",
    "\tunique_F, unique_indices = np.unique(res.F[fronts], axis=0, return_index=True)\n",
    "\n",
    "\t# Extract best instances for minority class\n",
    "\tif minority_class == 0:\n",
    "\t\tbest_instance_idx = np.argmin(unique_F[0,:])\n",
    "\telse:\n",
    "\t\tbest_instance_idx = np.argmin(unique_F[:,0])\n",
    "\n",
    "\tbest_instance = res.X[unique_indices[best_instance_idx]]\n",
    "\tx_train_filtered, y_train_filtered = X_train[best_instance], y_train[best_instance]\n",
    "\tnum_instance_in_best_solution = y_train_filtered.shape[0]\n",
    "\t_, _, optimized_IR = set_summary(y_train_filtered, 'y', print_res=False)\n",
    "\t\n",
    "\t# Calculate the optimized accuracy of the best instance on test set and validation set\n",
    "\toptimized_knn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\toptimized_knn.fit(x_train_filtered, y_train_filtered)\n",
    "\tclass_0_optimized_testAcc, class_1_optimized_testAcc, optimized_testAcc = class_based_accuracy(optimized_knn, X_test, y_test)\n",
    "\tclass_0_optimized_valAcc, class_1_optimized_valAcc, optimized_valAcc = class_based_accuracy(optimized_knn, X_val, y_val)\n",
    "\n",
    "\ttest_pareto_front = []\n",
    "\tnum_examples_in_best_instance_on_test = -1\n",
    "\tbest_error_instance_on_test = 1\n",
    "\tfor instance in res.X[unique_indices]:\n",
    "\t\tx_filtered, y_filtered = X_train[instance], y_train[instance]\n",
    "\t\tif x_filtered.shape[0] < N_NEIGHBOURS: test_pareto_front.append([1, 1])\n",
    "\t\telse:\n",
    "\t\t\tknn = KNeighborsClassifier(n_neighbors=N_NEIGHBOURS)\n",
    "\t\t\tknn.fit(x_filtered, y_filtered)\n",
    "\t\t\t\n",
    "\t\t\tclass_1_indices = np.where(y_test==1)\n",
    "\t\t\tclass_0_indices = np.where(y_test==0)\n",
    "\n",
    "\t\t\tclass_1_x_val = X_test[class_1_indices]\n",
    "\t\t\tclass_0_x_val = X_test[class_0_indices]\n",
    "\t\t\tclass_1_y_val = y_test[class_1_indices]\n",
    "\t\t\tclass_0_y_val = y_test[class_0_indices]\n",
    "\t\t\t\n",
    "\t\t\tclass_1_pred = knn.predict(class_1_x_val)\n",
    "\t\t\tclass_1_acc = accuracy_score(class_1_y_val, class_1_pred)\n",
    "\n",
    "\t\t\tclass_0_pred = knn.predict(class_0_x_val)\n",
    "\t\t\tclass_0_acc = accuracy_score(class_0_y_val, class_0_pred)\n",
    "\n",
    "\t\t\tif minority_class == 0:\n",
    "\t\t\t\tif (1-class_0_acc) < best_error_instance_on_test:\n",
    "\t\t\t\t\tnum_examples_in_best_instance_on_test = x_filtered.shape[0]\n",
    "\t\t\t\t\tbest_error_instance_on_test = (1-class_0_acc)\n",
    "\t\t\telse:\n",
    "\t\t\t\tif (1-class_1_acc) < best_error_instance_on_test:\n",
    "\t\t\t\t\tnum_examples_in_best_instance_on_test = x_filtered.shape[0]\n",
    "\t\t\t\t\tbest_error_instance_on_test = (1-class_1_acc)\n",
    "\n",
    "\t\t\ttest_pareto_front.append([1-class_0_acc, 1-class_1_acc])\n",
    "\n",
    "\tx1, y1 = [row[0] for row in unique_F], [row[1] for row in unique_F]\n",
    "\tx2, y2 = [row[0] for row in test_pareto_front], [row[1] for row in test_pareto_front]\n",
    "\tplt.ylim((0, 1))\n",
    "\tplt.xlim((0, 1))\n",
    "\tplt.title(name)\n",
    "\tplt.ylabel(f\"f1 {'*' if minority_class == 0 else ''}\")\n",
    "\tplt.xlabel(f\"f2 {'*' if minority_class == 1 else ''}\")\n",
    "\tplt.scatter(x1, y1, c='b')\n",
    "\tplt.scatter(x2, y2, c='r')\n",
    "\tplt.show()\n",
    "\n",
    "\treturn {\"Label\": name, \n",
    "\t\t    \"Num Features\": num_features, \n",
    "\t\t    \"Num Examples\": num_examples,\n",
    "\t\t    \"Training Size\": X_train.shape[0],\n",
    "\t\t    \"Minority Class\": minority_class,\n",
    "\t\t    \n",
    "\t\t\t\"Base - Test C0 Acc\": round(class_0_baseline_testAcc*100,2), \n",
    "\t\t    \"Base - Test C1 Acc\": round(class_1_baseline_testAcc*100,2), \n",
    "\t\t    \"Base - Test Acc\": round(baseline_testAcc*100,2), \n",
    "\n",
    "\t\t\t\"Base - Val C0 Acc\": round(class_0_baseline_valAcc*100,2), \n",
    "\t\t    \"Base - Val C1 Acc\": round(class_1_baseline_valAcc*100,2), \n",
    "\t\t    \"Base - Val Acc\": round(baseline_valAcc*100,2), \n",
    "\n",
    "\t\t    \"Optimized - Test C0 Acc\": round(class_0_optimized_testAcc*100,2), \n",
    "\t\t    \"Optimized - Test C1 Acc\": round(class_1_optimized_testAcc*100,2), \n",
    "\t\t    \"Optimized - Test Acc\": round(optimized_testAcc*100,2), \n",
    "\t\t\t\"Num Examples for Test Best\": num_examples_in_best_instance_on_test,\n",
    "\t\t\t\n",
    "\t\t\t\"Optimized - Val C0 Acc\": round(class_0_optimized_valAcc*100,2), \n",
    "\t\t    \"Optimized - Val C1 Acc\": round(class_1_optimized_valAcc*100,2), \n",
    "\t\t    \"Optimized - Val Acc\": round(optimized_valAcc*100,2), \n",
    "\t\t\t\"Num Examples for Val Best\": num_instance_in_best_solution,\n",
    "\t\t    \n",
    "\t\t\t\"Baseline IR\": train_baseline_IR,\n",
    "\t\t    \"Optimized IR\": optimized_IR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and packaging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RjKim\\AppData\\Local\\Temp\\ipykernel_1780\\169272633.py:184: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(path, delimiter=', ')\n",
      "C:\\Users\\RjKim\\AppData\\Local\\Temp\\ipykernel_1780\\169272633.py:184: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(path, delimiter=', ')\n",
      "C:\\Users\\RjKim\\AppData\\Local\\Temp\\ipykernel_1780\\169272633.py:184: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(path, delimiter=', ')\n",
      "C:\\Users\\RjKim\\AppData\\Local\\Temp\\ipykernel_1780\\169272633.py:184: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(path, delimiter=', ')\n",
      "C:\\Users\\RjKim\\AppData\\Local\\Temp\\ipykernel_1780\\169272633.py:184: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(path, delimiter=', ')\n",
      "C:\\Users\\RjKim\\AppData\\Local\\Temp\\ipykernel_1780\\169272633.py:184: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(path, delimiter=', ')\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tdatasets.append(parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random and biased initial population for objectices --> Error and number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3638434715.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    if init\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "runs = {}\n",
    "for iter in range(10):\n",
    "\tfor data_option in ['over_sample', 'regular_sample']:\n",
    "\t\tfor init_pop in ['rand', 'bias']:\n",
    "\t\t\tfor optimization in ['MinMajAcc', '2Obj', '3Obj']:\n",
    "\t\t\t\tfor folder in os.listdir('Datasets'):\n",
    "\t\t\t\t\tover_sample = False if data_option == \"regular_sample\" else True\n",
    "\t\t\t\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=over_sample)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif optimization == \"MinMajAcc\":\n",
    "\t\t\t\t\t\tif init_pop == \"rand\":\n",
    "\t\t\t\t\t\t\tresult = execute_class_sensitive_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj_MinMaxAcc, BinaryRandomSampling())\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tresult = execute_class_sensitive_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj_MinMaxAcc, BiasedBinarySampling(y_train, 0.5, 0.7))\n",
    "\n",
    "\t\t\t\t\telif optimization == \"2Obj\":\n",
    "\t\t\t\t\t\tif init_pop == \"rand\":\n",
    "\t\t\t\t\t\t\tresult = execute_regular_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj, BinaryRandomSampling())\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tresult = execute_regular_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj, BiasedBinarySampling(y_train, 0.5, 0.7))\n",
    "\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tif init_pop == \"rand\":\n",
    "\t\t\t\t\t\t\tresult = execute_regular_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_3_Obj, BinaryRandomSampling())\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tresult = execute_regular_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_3_Obj, BiasedBinarySampling(y_train, 0.5, 0.7))\n",
    "\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tfor iter in range(10):\n",
    "\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=False)\n",
    "\t\tname = f\"RegSample-MinMajAcc-Rand-{name}\"\n",
    "\t\titer_results.append(execute_class_sensitive_optimization(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj_MinMaxAcc, BinaryRandomSampling()))\n",
    "\n",
    "\n",
    "\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tfor iter in range(10):\n",
    "\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=False)\n",
    "\t\tname = f\"RegSample-2Obj-Bias-{name}\"\n",
    "\t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj, BiasedBinarySampling(y_train, 0.5, 0.7)))\n",
    "\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tfor iter in range(10):\n",
    "\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=False)\n",
    "\t\tname = f\"RegSample-2Obj-Rand-{name}\"\n",
    "\t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj, BinaryRandomSampling()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tfor iter in range(10):\n",
    "\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=False)\n",
    "\t\tname = f\"RegSample-3Obj-Bias-{name}\"\n",
    "\t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_3_Obj, BiasedBinarySampling(y_train, 0.5, 0.7)))\n",
    "\n",
    "for folder in os.listdir('Datasets'):\n",
    "\tfor iter in range(10):\n",
    "\t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=False)\n",
    "\t\tname = f\"RegSample-3Obj-Rand-{name}\"\n",
    "\t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_3_Obj, BinaryRandomSampling()))\n",
    "\n",
    "\n",
    "#---------------------------------------\n",
    "\n",
    "# iter_results = []\n",
    "# for folder in os.listdir('Datasets'):\n",
    "# \tfor iter in range(10):\n",
    "# \t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=True)\n",
    "# \t\tname = f\"OverUnderSample-MinMajAcc-Bias-{name}\"\n",
    "# \t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj_MinMaxAcc, BiasedBinarySampling(y_train, 0.5, 0.7)))\n",
    "\n",
    "# for folder in os.listdir('Datasets'):\n",
    "# \tfor iter in range(10):\n",
    "# \t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=True)\n",
    "# \t\tname = f\"OverUnderSample-MinMajAcc-Rand-{name}\"\n",
    "# \t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj_MinMaxAcc, BinaryRandomSampling()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for folder in os.listdir('Datasets'):\n",
    "# \tfor iter in range(10):\n",
    "# \t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=True)\n",
    "# \t\tname = f\"OverUnderSample-2Obj-Bias-{name}\"\n",
    "# \t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj, BiasedBinarySampling(y_train, 0.5, 0.7)))\n",
    "\n",
    "# for folder in os.listdir('Datasets'):\n",
    "# \tfor iter in range(10):\n",
    "# \t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=True)\n",
    "# \t\tname = f\"OverUnderSample-2Obj-Rand-{name}\"\n",
    "# \t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_2_Obj, BinaryRandomSampling()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for folder in os.listdir('Datasets'):\n",
    "# \tfor iter in range(10):\n",
    "# \t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=True)\n",
    "# \t\tname = f\"OverUnderSample-3Obj-Bias-{name}\"\n",
    "# \t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_3_Obj, BiasedBinarySampling(y_train, 0.5, 0.7)))\n",
    "\n",
    "# for folder in os.listdir('Datasets'):\n",
    "# \tfor iter in range(10):\n",
    "# \t\tX, y, X_train, X_val, X_test, y_train, y_val, y_test, name = parse_dataset(os.path.join('Datasets', folder, f\"{folder}.csv\"), folder, over_sample=True)\n",
    "# \t\tname = f\"OverUnderSample-3Obj-Rand-{name}\"\n",
    "# \t\titer_results.append(execute_Iter1(X, y, X_train, X_val, X_test, y_train, y_val, y_test, name, InstanceSelectionProblem_3_Obj, BinaryRandomSampling()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summations = {}\n",
    "for result in iter_results:\n",
    "\t\n",
    "\tif result['Label'] not in summations:\n",
    "\t\tsummations[result['Label']] = {}\n",
    "\t\tfor key in result:\n",
    "\t\t\tif isinstance(result[key], float) or isinstance(result[key], int):\n",
    "\t\t\t\tsummations[result['Label']][key] = 0\n",
    "\t\n",
    "\tfor key in result:\n",
    "\t\tif key in summations[result['Label']]:\n",
    "\t\t\tsummations[result['Label']][key] += result[key]\n",
    "\t\n",
    "\t\n",
    "\n",
    "averages = []\n",
    "for label in summations:\n",
    "\ttemp = {}\n",
    "\tfor key in summations[label]:\n",
    "\t\ttemp[key] = summations[label][key] / 10\n",
    "\t\n",
    "\ttemp[\"Label\"] = label\n",
    "\taverages.append(temp)\n",
    "\n",
    "pd.DataFrame(averages).to_csv(\"output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
